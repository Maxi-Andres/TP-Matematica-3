{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Cosas que hacer:\n",
    "- Ver como hacer para que alguien pueda dibujar un numero y probar la red\n",
    "- Ver como lograr convertir imagenes para que la red lo entienda\n",
    "- Entrenarla con los numeros rotados 90°\n",
    "- Que una de las salidas posibles sea Nan\n",
    "- Como hacer que una persona escriba un numero para que lo use la red\n",
    "- \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.38591229\n",
      "Iteration 2, loss = 0.16769108\n",
      "Iteration 3, loss = 0.12181802\n",
      "Iteration 4, loss = 0.09769061\n",
      "Iteration 5, loss = 0.08105783\n",
      "Iteration 6, loss = 0.06908477\n",
      "Iteration 7, loss = 0.05839070\n",
      "Iteration 8, loss = 0.05098693\n",
      "Iteration 9, loss = 0.04701358\n",
      "Iteration 10, loss = 0.04090294\n",
      "Iteration 11, loss = 0.03471654\n",
      "Iteration 12, loss = 0.03233246\n",
      "Iteration 13, loss = 0.02759029\n",
      "Iteration 14, loss = 0.02440189\n",
      "Iteration 15, loss = 0.02316396\n",
      "Iteration 16, loss = 0.01916630\n",
      "Iteration 17, loss = 0.01828377\n",
      "Iteration 18, loss = 0.01512866\n",
      "Iteration 19, loss = 0.01245130\n",
      "Iteration 20, loss = 0.01064614\n",
      "Iteration 21, loss = 0.00887646\n",
      "Iteration 22, loss = 0.00912056\n",
      "Iteration 23, loss = 0.00659234\n",
      "Iteration 24, loss = 0.00468439\n",
      "Iteration 25, loss = 0.00388060\n",
      "Iteration 26, loss = 0.00318033\n",
      "Iteration 27, loss = 0.00222766\n",
      "Iteration 28, loss = 0.00206562\n",
      "Iteration 29, loss = 0.00170673\n",
      "Iteration 30, loss = 0.00152889\n",
      "Iteration 31, loss = 0.00138329\n",
      "Iteration 32, loss = 0.00133623\n",
      "Iteration 33, loss = 0.00122144\n",
      "Iteration 34, loss = 0.00121324\n",
      "Iteration 35, loss = 0.00110816\n",
      "Iteration 36, loss = 0.00105642\n",
      "Iteration 37, loss = 0.00100911\n",
      "Iteration 38, loss = 0.00098488\n",
      "Iteration 39, loss = 0.00095714\n",
      "Iteration 40, loss = 0.00092685\n",
      "Iteration 41, loss = 0.00089291\n",
      "Iteration 42, loss = 0.00087912\n",
      "Iteration 43, loss = 0.00084421\n",
      "Iteration 44, loss = 0.00082953\n",
      "Iteration 45, loss = 0.00080458\n",
      "Iteration 46, loss = 0.00078607\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Precisión del modelo: 97.31%\n"
     ]
    }
   ],
   "source": [
    "# El codigo este utiliza la libreira sklearn para la red neuronal, asi puedo hacer pruebas de manera mas facil, tambien utiliza OpenML para descargar el dataset MNIST y la red neuronal MLP \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml # Permite descargar datasets desde OpenML.\n",
    "from sklearn.model_selection import train_test_split # esto me permite dividir los datos en conjuntos de entrenamiento y prueba de forma aleatoria.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# (Multi-layer Perceptron Classifier), un tipo de red neuronal de scikit-learn que se usa para clasificación. Esta red neuronal puede aprender a \n",
    "# partir de datos etiquetados y ajustar los pesos de sus neuronas en varias capas ocultas.\n",
    "from sklearn.metrics import accuracy_score # Mide la precisión de un modelo al comparar las predicciones del modelo con las etiquetas reales.\n",
    "\n",
    "# Descargar el dataset MNIST desde OpenML se pone el nombre y la versión\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "\n",
    "# X Es una matriz donde cada fila representa una imagen y cada (atributo, columna, caracteristica o como se le diga) corresponde a uno de los 784 píxeles de la imagen (28x28 píxeles).\n",
    "# y contiene las etiquetas o clases (0-9, el número representado por la imagen)\n",
    "# Ambas tienen 70,000 filas\n",
    "X, y = mnist['data'], mnist['target']\n",
    "# La razón por la que en el código se utiliza mnist['data'] y mnist['target'] tiene que ver con cómo scikit-learn organiza y presenta los datos al cargar un dataset, no con el formato ARFF en si, ya que si lo buscas no vas a encontrar la columna 'target'\n",
    "\n",
    "# Se convierte la clase {0,1...9} a un entero que ocupe 8 bits por las dudas\n",
    "y = y.astype(np.int8)\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# El parámetro random_state es una semilla que se utiliza para generar los números aleatorios de manera reproducible. Al usar un valor fijo como 42, se garantiza que cada vez que ejecutes el código, la división sea la misma.\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0     # Normalizar los datos del 0 al 1 para que funcione mejor por la funcion sigmoide???????\n",
    "\n",
    "# Crear el clasificador MLP\n",
    "# Esta entiende automaticamente que la funcion de la capa de salida es softmax y que tiene que tener 10 salidas ya que hay 10 clases\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64,32), max_iter=80, activation='relu',\n",
    "                    solver='sgd', verbose=1, random_state=42,\n",
    "                    learning_rate_init=0.02, batch_size=100)\n",
    "\n",
    "# Este código configura una red neuronal con:\n",
    "# hidden_layer_sizes: Una sola capa oculta de 64 neuronas.\n",
    "# max_iter: Máximo de epochs para el entrenamiento.\n",
    "# alpha: Controla la regularización L2 (decay de pesos), que ayuda a prevenir el sobreajuste del modelo.\n",
    "# solver: Algoritmo utilizado para optimizar el modelo (Stop-Gradient Descent).\n",
    "# verbose: alpha=1e-4 lo pongo aca porque no lo entendi bien....\n",
    "# random_state: es la semilla aleatoria que se utiliza\n",
    "# learning_rate_init: learning rate inicial\n",
    "# batch_size: batch size....\n",
    "\n",
    "# Entrenar la red neuronal\n",
    "mlp.fit(X_train, y_train)\n",
    "# Esto hace Forward Propagation, Cálculo de Pérdida, Backpropagation y lo repite por la cantidad de epochs\n",
    "\n",
    "# Realizar predicciones sobre el conjunto de prueba\n",
    "y_pred = mlp.predict(X_test)\n",
    "# Esto hace Forward Propagation, osea nada, es ya la red entrenada que la testeas\n",
    "\n",
    "# Calcular la precisión\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión del modelo: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Si pone esto \"ConvergenceWarning\" significa que no encontro un minimo de la funcion cuadratica (Costo) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Cosas varias:\n",
    "\n",
    "- El archivo mnist_784.arff esta ahi porque yo lo queria ver pero se usa el que esta online no ese\n",
    "- @RELATION DATA=train-images.idx3-ubyte-LABELS=train-labels.idx1-ubyte\n",
    "- @RELATION = Este es un campo en el formato ARFF que se utiliza para definir el nombre o relación del dataset.\n",
    "- train-images.idx3-ubyte = Hace referencia a un archivo que contiene las imágenes del conjunto de entrenamiento en formato IDX3 (un formato binario utilizado para almacenar imágenes en el dataset MNIST). Estas imágenes son de 28x28 píxeles en escala de grises.\n",
    "- train-labels.idx1-ubyte = Hace referencia a otro archivo que contiene las etiquetas o clases correspondientes a las imágenes de entrenamiento. En este caso, las etiquetas son números entre 0 y 9, indicando el dígito que aparece en cada imagen. El - formato IDX1 es un formato binario que almacena las etiquetas.\n",
    "- DATA: Indica que la relación principal en el archivo es un conjunto de datos de imágenes.\n",
    "- train-images.idx3-ubyte: Este es el archivo que contiene los datos de las imágenes de entrenamiento en el formato binario IDX3.\n",
    "- LABELS: Indica que el archivo relacionado contiene las etiquetas asociadas a las imágenes.\n",
    "- train-labels.idx1-ubyte: Es el archivo que contiene las etiquetas (o clases) de las imágenes en el formato binario IDX1.\n",
    "\n",
    "- Resumen: Este campo está describiendo la relación entre las imágenes de entrenamiento y sus etiquetas. El archivo de imágenes train-images.idx3-ubyte contiene los píxeles de las imágenes, y el archivo train-labels.idx1-ubyte contiene las etiquetas numéricas que identifican el dígito (0-9) que cada imagen representa.\n",
    "\n",
    "- En el contexto de un archivo ARFF, la palabra \"atributo\" se utiliza formalmente para referirse a lo que en otros contextos (como un archivo CSV) podríamos llamar una \"columna\".\n",
    "\n",
    "- @ATTRIBUTE pixel1\treal = esto significa que el atributo pixel1 (columna) contiene numeros reales\n",
    "\n",
    "- @ATTRIBUTE class\t{0,1,2,3,4,5,6,7,8,9} = class representa la etiqueta o clase asociada con cada instancia del dataset. En el contexto del dataset MNIST, class sería el número que representa la imagen, es decir, el dígito escrito a mano en la imagen.\n",
    "\n",
    "- @DATA\n",
    "0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,18,18,18,126,136,175,26,166,255,247,127,0,0,0,0,0,0,0,0,0,0,0,0,30,36,94,154,170,253,253,253,253,253,225,172,253,242,195,64,0,0,0,0,0,0,0,0,0,0,0,49,238,253,253,253,253,253,253,253,253,251,93,\n",
    "82,82,56,39,0,0,0,0,0,0,0,0,0,0,0,0,18,219,253,253,253,253,253,198,182,247,241,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,156,107,253,253,205,11,0,43,154,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,154,253,90,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "0,0,139,253,190,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,190,253,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,241,225,160,108,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,81,240,253,253,119,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "0,0,0,0,0,0,0,0,45,186,253,253,150,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,93,252,253,187,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,249,253,249,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,46,130,183,253,253,207,2,0,0,0,0,0,0,0,0,\n",
    "0,0,0,0,0,0,0,0,0,0,0,39,148,229,253,253,253,250,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,114,221,253,253,253,253,201,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,66,213,253,253,253,253,198,81,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,171,219,253,253,253,\n",
    "253,195,80,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,172,226,253,253,253,253,244,133,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,136,253,253,253,212,135,132,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5\n",
    "\n",
    "- Cada valor es una columna las llamadas como \"pixel\", el ultimo valor, en este caso un 5 representa la clase que es (que numero representa)\n",
    "\n",
    "- Cuando usas la función fetch_openml() de scikit-learn para descargar el dataset MNIST, este se convierte en un diccionario de datos que sigue una convención específica de scikit-learn para facilitar el uso de los datasets. Este diccionario tiene claves comunes para acceder a diferentes partes del conjunto de datos\n",
    "\n",
    "\n",
    "1. **`mnist['data']`**:\n",
    "   - aca se almacenan los **atributos** (es decir, las características de cada ejemplo del dataset, que en el caso de MNIST son los valores de los píxeles de las imágenes).\n",
    "   - **`mnist['data']`** es una matriz donde cada fila representa una imagen, y cada columna corresponde a un píxel (28x28 = 784 características).\n",
    "\n",
    "2. **`mnist['target']`**:\n",
    "   - aca se almacenan las **etiquetas** o **clases** de cada imagen (en el caso de MNIST, el dígito que representa la imagen, que puede ser un número entre 0 y 9).\n",
    "   - **`mnist['target']`** es un vector que contiene la etiqueta correspondiente para cada fila de **`mnist['data']`**.\n",
    "   - El término **`target`** es una convención que usa scikit-learn para referirse a las **etiquetas de clasificación**.\n",
    "\n",
    "#### ¿Por qué no aparece \"target\" en el archivo ARFF?\n",
    "\n",
    "El archivo **ARFF** tiene una estructura diferente, donde no se utiliza la palabra **\"target\"**. En su lugar, las etiquetas se definen en la sección de **atributos**. Por ejemplo, en el caso de MNIST, el archivo ARFF tiene una línea como esta:\n",
    "\n",
    "```arff\n",
    "@ATTRIBUTE class {0,1,2,3,4,5,6,7,8,9}\n",
    "```\n",
    "\n",
    "Esto significa que el último atributo de cada fila en la sección **`@DATA`** es la **clase** o **etiqueta** de la imagen (el dígito que representa la imagen).\n",
    "\n",
    "#### ¿Cómo scikit-learn maneja esto?\n",
    "\n",
    "Cuando cargas el archivo con **scikit-learn** usando `fetch_openml()`, el código automáticamente:\n",
    "\n",
    "- **Separa** los atributos (los valores de los píxeles) y las etiquetas (las clases).\n",
    "- Coloca los atributos en **`mnist['data']`** y las etiquetas en **`mnist['target']`**.\n",
    "\n",
    "En resumen, la palabra **`target`** y **`data`** es simplemente una convención de **scikit-learn** para identificar la **columna de etiquetas** en datasets de clasificación. No aparece en el archivo ARFF, pero scikit-learn lo gestiona automáticamente cuando cargas el dataset.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Recursos utilizados:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "papa fritas\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
